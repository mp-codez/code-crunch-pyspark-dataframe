9from fastapi import FastAPI, HTTPException, Header, Depends
from pydantic import BaseModel
from datetime import datetime
import boto3
import sqlite3

# Constants
S3_ENDPOINT = "http://<s3-gateway-host>:9878"
DEFAULT_REGION = "us-east-1"
SQLITE_DB = "bucket_access.db"
DEFAULT_TEAM_ID = "team_001"
VALID_TOKEN = "supersecrettoken123"  # You can later load from env or DB

app = FastAPI()

# Input Model
class BucketCreateRequest(BaseModel):
    bucket_name: str

# DB Setup
def init_db():
    with sqlite3.connect(SQLITE_DB) as conn:
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS bucket_access (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                team_id TEXT NOT NULL,
                bucket_name TEXT UNIQUE NOT NULL,
                created_at TEXT NOT NULL
            )
        """)
        conn.commit()

# S3 Client
def get_s3_client():
    return boto3.client(
        "s3",
        endpoint_url=S3_ENDPOINT,
        region_name=DEFAULT_REGION
    )

# Token Auth Dependency
def validate_token(authorization: str = Header(...)):
    if not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Invalid Authorization header format")
    token = authorization.split(" ")[1]
    if token != VALID_TOKEN:
        raise HTTPException(status_code=403, detail="Invalid or expired token")

# POST /create_new_bucket
@app.post("/create_new_bucket")
def create_new_bucket(request: BucketCreateRequest, _: None = Depends(validate_token)):
    init_db()
    s3 = get_s3_client()

    # Check if bucket already exists
    with sqlite3.connect(SQLITE_DB) as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT 1 FROM bucket_access WHERE bucket_name = ?", (request.bucket_name,))
        if cursor.fetchone():
            raise HTTPException(status_code=400, detail="Bucket already exists")

    # Create bucket in S3
    try:
        s3.create_bucket(Bucket=request.bucket_name)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error creating bucket in S3: {e}")

    # Insert into DB
    with sqlite3.connect(SQLITE_DB) as conn:
        cursor = conn.cursor()
        cursor.execute(
            "INSERT INTO bucket_access (team_id, bucket_name, created_at) VALUES (?, ?, ?)",
            (DEFAULT_TEAM_ID, request.bucket_name, datetime.utcnow().isoformat())
        )
        conn.commit()

    return {"message": f"Bucket {request.bucket_name} created successfully"}

# POST /get_list_of_bucket
@app.post("/get_list_of_bucket")
def get_list_of_bucket(_: None = Depends(validate_token)):
    init_db()
    with sqlite3.connect(SQLITE_DB) as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT bucket_name, created_at FROM bucket_access")
        rows = cursor.fetchall()
        buckets = [{"bucketName": row[0], "creationDate": row[1]} for row in rows]

    return {"message": "Buckets retrieved successfully", "buckets": buckets}


========
from fastapi import FastAPI, Depends, Header, HTTPException
from fastapi.security import APIKeyHeader
from typing import Optional

app = FastAPI()

API_KEY_NAME = "Authorization"
API_KEY = "YOUR_SECRET_TOKEN"  # Replace with your real token
api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)

def validate_token(api_key: Optional[str] = Depends(api_key_header)):
    if api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Invalid or missing token")

@app.post("/create_new_bucket", dependencies=[Depends(validate_token)])
async def create_bucket():
    return {"message": "Bucket created"}

@app.post("/get_list_of_bucket", dependencies=[Depends(validate_token)])
async def get_buckets():
    return {"buckets": []}


=========================================
import boto3
import sqlite3
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI()

DB_PATH = "buckets.db"
TEAM_ID = "team123"

# Configure your S3 Endpoint and Keys
OZONE_ENDPOINT = "http://<s3g-host>:9878"  # Change this
AWS_ACCESS_KEY_ID = "your-access-key"
AWS_SECRET_ACCESS_KEY = "your-secret-key"

s3_client = boto3.client(
    's3',
    endpoint_url=OZONE_ENDPOINT,
    aws_access_key_id=AWS_ACCESS_KEY_ID,
    aws_secret_access_key=AWS_SECRET_ACCESS_KEY
)

class RenameBucketRequest(BaseModel):
    old_bucket_name: str
    new_bucket_name: str

@app.post("/rename_bucket_name")
def rename_bucket(request: RenameBucketRequest):
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # Check if old bucket exists in DB
    cursor.execute("SELECT 1 FROM bucket_access WHERE bucket_name = ? AND team_id = ?", (request.old_bucket_name, TEAM_ID))
    if cursor.fetchone() is None:
        conn.close()
        raise HTTPException(status_code=404, detail="Old bucket not found in DB")

    # Check if new bucket already exists
    cursor.execute("SELECT 1 FROM bucket_access WHERE bucket_name = ? AND team_id = ?", (request.new_bucket_name, TEAM_ID))
    if cursor.fetchone() is not None:
        conn.close()
        raise HTTPException(status_code=400, detail="New bucket name already exists")

    # Step 1: Create new bucket
    try:
        s3_client.create_bucket(Bucket=request.new_bucket_name)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create new bucket: {str(e)}")

    # Step 2: Copy objects from old to new
    try:
        old_objects = s3_client.list_objects_v2(Bucket=request.old_bucket_name)
        if 'Contents' in old_objects:
            for obj in old_objects['Contents']:
                copy_source = {'Bucket': request.old_bucket_name, 'Key': obj['Key']}
                s3_client.copy_object(CopySource=copy_source, Bucket=request.new_bucket_name, Key=obj['Key'])
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error copying objects: {str(e)}")

    # Step 3: Delete old bucket
    try:
        if 'Contents' in old_objects:
            for obj in old_objects['Contents']:
                s3_client.delete_object(Bucket=request.old_bucket_name, Key=obj['Key'])
        s3_client.delete_bucket(Bucket=request.old_bucket_name)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error deleting old bucket: {str(e)}")

    # Step 4: Update bucket_access table
    try:
        cursor.execute("UPDATE bucket_access SET bucket_name = ? WHERE bucket_name = ? AND team_id = ?",
                       (request.new_bucket_name, request.old_bucket_name, TEAM_ID))
        conn.commit()
    finally:
        conn.close()

    return {"message": f"Bucket {request.old_bucket_name} renamed to {request.new_bucket_name}"}


================
from fastapi import FastAPI, File, UploadFile, Form, Depends, Header, HTTPException
from pydantic import BaseModel
import boto3
import sqlite3
import io

app = FastAPI()

# Constants
OZONE_S3_ENDPOINT = "http://<s3-gateway-host>:9878"  # Replace with your S3 URL
ACCESS_KEY = "your-access-key"
SECRET_KEY = "your-secret-key"
API_KEY = "YOUR_SECRET_TOKEN"
OZONE_VOLUME = "s3v"

# Boto3 client
s3_client = boto3.client(
    's3',
    endpoint_url=OZONE_S3_ENDPOINT,
    aws_access_key_id=ACCESS_KEY,
    aws_secret_access_key=SECRET_KEY,
)

# Token validation
def validate_token(authorization: str = Header(...)):
    if authorization != API_KEY:
        raise HTTPException(status_code=401, detail="Invalid token")

@app.post("/upload_file", dependencies=[Depends(validate_token)])
async def upload_file(
    bucket_name: str = Form(...),
    file: UploadFile = File(...)
):
    try:
        # Upload the file
        file_bytes = await file.read()
        response = s3_client.put_object(
            Bucket=bucket_name,
            Key=file.filename,
            Body=io.BytesIO(file_bytes)
        )

        return {
            "message": f"File {file.filename} uploaded successfully to bucket {bucket_name}",
            "response": {
                "ResponseMetadata": {
                    "RequestId": response["ResponseMetadata"].get("RequestId"),
                    "HostId": response["ResponseMetadata"].get("HostId", ""),
                    "HttpStatusCode": response["ResponseMetadata"].get("HTTPStatusCode"),
                    "HttpHeaders": response["ResponseMetadata"].get("HTTPHeaders", {}),
                    "RetryAttempts": response["ResponseMetadata"].get("RetryAttempts", 0)
                },
                "ETag": response.get("ETag", "")
            },
            "filename": file.filename
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"File upload failed: {str(e)}")



========/============
from fastapi import FastAPI, UploadFile, File, Form, Depends, HTTPException
import boto3
from botocore.exceptions import BotoCoreError, ClientError

app = FastAPI()

def validate_token(secret_access_key: str):
    return secret_access_key

@app.post("/upload_large_file_with_metadata")
async def upload_file(
    bucket_name: str = Form(...),
    file_name: str = Form(...),
    file: UploadFile = File(...),
    secret_access_key: str = Depends(validate_token)
):
    try:
        s3_client = boto3.client(
            's3',
            endpoint_url='http://<your-ozone-endpoint>',
            aws_access_key_id='your-access-key',
            aws_secret_access_key=secret_access_key
        )

        # Step 1: Initiate multipart upload
        mpu = s3_client.create_multipart_upload(Bucket=bucket_name, Key=file_name)
        upload_id = mpu["UploadId"]

        part_size = 50 * 1024 * 1024  # 50 MB
        parts = []
        part_number = 1

        while True:
            chunk = await file.read(part_size)
            if not chunk:
                break

            response = s3_client.upload_part(
                Bucket=bucket_name,
                Key=file_name,
                PartNumber=part_number,
                UploadId=upload_id,
                Body=chunk
            )

            parts.append({
                "PartNumber": part_number,
                "ETag": response["ETag"]
            })
            part_number += 1

        # Step 3: Complete multipart upload
        result = s3_client.complete_multipart_upload(
            Bucket=bucket_name,
            Key=file_name,
            UploadId=upload_id,
            MultipartUpload={"Parts": parts}
        )

        # Return full metadata response
        return {
            "message": f"File '{file_name}' uploaded successfully to bucket '{bucket_name}'",
            "filename": file_name,
            "response": {
                "ETag": result.get("ETag"),
                "Location": result.get("Location"),
                "ResponseMetadata": result.get("ResponseMetadata", {})
            }
        }

    except (BotoCoreError, ClientError) as e:
        raise HTTPException(status_code=500, detail=str(e))


======================
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import boto3
import sqlite3

app = FastAPI()

class BucketListRequest(BaseModel):
    team_id: str
    secret_access_key: str

@app.post("/list_buckets")
async def list_buckets(payload: BucketListRequest):
    try:
        # Connect to SQLite
        conn = sqlite3.connect("buckets.db")
        cursor = conn.cursor()

        # Get buckets for the team_id
        cursor.execute("SELECT bucket_name, creation_date FROM bucket_access WHERE team_id = ?", (payload.team_id,))
        records = cursor.fetchall()

        if not records:
            return {"message": "No buckets found for this team", "buckets": []}

        # Fetch bucket list from Ozone via boto3
        s3_client = boto3.client(
            's3',
            endpoint_url='http://<your-ozone-endpoint>',
            aws_access_key_id='your-access-key',
            aws_secret_access_key=payload.secret_access_key
        )

        existing_buckets = {b['Name'] for b in s3_client.list_buckets().get('Buckets', [])}

        filtered = [
            {"bucketName": name, "creationDate": date}
            for (name, date) in records if name in existing_buckets
        ]

        return {"message": "Buckets retrieved successfully", "buckets": filtered}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))



=========
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import boto3
from botocore.exceptions import ClientError

app = FastAPI()

# Request payload model
class BucketListRequest(BaseModel):
    bucket_name: str
    secret_access_key: str  # Optional token-based access

@app.post("/getFileListInBucket")
def get_file_list(payload: BucketListRequest):
    try:
        # Initialize S3 client for Apache Ozone
        s3_client = boto3.client(
            's3',
            endpoint_url='http://<your-ozone-s3-endpoint>',  # Replace with actual endpoint
            aws_access_key_id='your-access-key',
            aws_secret_access_key=payload.secret_access_key,
        )

        # List objects in the bucket
        response = s3_client.list_objects_v2(Bucket=payload.bucket_name)

        if 'Contents' not in response:
            return {"message": "No files found in bucket.", "files": []}

        files = []
        for obj in response['Contents']:
            key = obj['Key']
            file_type = key.split('.')[-1] if '.' in key else 'unknown'

            files.append({
                "file": key,
                "size": obj['Size'],
                "date_modified": obj['LastModified'].isoformat(),
                "type": file_type
            })

        return {
            "message": f"Files listed successfully in bucket {payload.bucket_name}",
            "files": files
        }

    except ClientError as e:
        code = e.response['Error']['Code']
        if code == 'NoSuchBucket':
            raise HTTPException(status_code=404, detail="Bucket does not exist.")
        else:
            raise HTTPException(status_code=500, detail=f"S3 Error: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Internal Error: {e}")



==================
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from datetime import datetime
import boto3
from botocore.exceptions import ClientError

app = FastAPI()

# Request Model
class RenameFileRequest(BaseModel):
    bucket_name: str
    file_old_name: str
    new_file_name: str
    secret_access_key: str

@app.post("/rename_file")
def rename_file(payload: RenameFileRequest):
    try:
        # Initialize S3 client for Apache Ozone
        s3_client = boto3.client(
            's3',
            endpoint_url='http://<your-ozone-s3-endpoint>',  # Replace with your endpoint
            aws_access_key_id='your-access-key',
            aws_secret_access_key=payload.secret_access_key,
        )

        # Copy the object
        copy_source = {
            'Bucket': payload.bucket_name,
            'Key': payload.file_old_name
        }

        s3_client.copy_object(
            Bucket=payload.bucket_name,
            CopySource=copy_source,
            Key=payload.new_file_name
        )

        # Delete the original object
        s3_client.delete_object(
            Bucket=payload.bucket_name,
            Key=payload.file_old_name
        )

        # Get metadata of new file
        head = s3_client.head_object(
            Bucket=payload.bucket_name,
            Key=payload.new_file_name
        )

        file_type = payload.new_file_name.split('.')[-1] if '.' in payload.new_file_name else 'unknown'

        return {
            "status": "File renamed successfully",
            "file_info": {
                "file": payload.new_file_name,
                "size": head['ContentLength'],
                "date_modified": head['LastModified'].isoformat(),
                "type": file_type
            }
        }

    except ClientError as e:
        raise HTTPException(status_code=500, detail=f"S3 Client Error: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Unexpected Error: {e}")